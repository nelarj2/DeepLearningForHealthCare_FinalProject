{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75196827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Conv1D, MaxPool1D, GlobalMaxPool1D, Embedding, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe4725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3383b05",
   "metadata": {
    "id": "b3383b05"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_add = pd.read_csv('/content/drive/MyDrive/Proj Data/ADMISSIONS.csv') # 58976 rows of data\n",
    "df_notes = pd.read_csv('/content/drive/MyDrive/Proj Data/NOTEEVENTS.csv.gz',dtype='unicode') # 2083180 rows of data\n",
    "df_codes = pd.read_csv('/content/drive/MyDrive/Proj Data/DIAGNOSES_ICD.csv') # 651047 rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y0ixHbyVEoxh",
   "metadata": {
    "id": "y0ixHbyVEoxh"
   },
   "source": [
    "# diagnosis dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "FN5bKbyOEpwK",
   "metadata": {
    "id": "FN5bKbyOEpwK"
   },
   "outputs": [],
   "source": [
    "# including only rows of data with heart failure ICD-9 codes\n",
    "hf_codes = ['39891', '40201', '40211', '40291', '40401', '40403', '40411', '40413', '40491', '40493', '4280', '4281', '42820','42821', '42822', '42823', '42830', '42831', '42832', '42833', '42840', '42841', '42842', '42843','4289']\n",
    "df_codes = df_codes.loc[df_codes.ICD9_CODE.isin(hf_codes)] # 651047 -> 21274 rows of data\n",
    "\n",
    "# list of subject_ids asociated with hf_codes\n",
    "hf_pid_list = df_codes[\"SUBJECT_ID\"].tolist() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ji9MahL5E8Ve",
   "metadata": {
    "id": "ji9MahL5E8Ve"
   },
   "source": [
    "# admissions dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "VDQj6RvxFEiX",
   "metadata": {
    "id": "VDQj6RvxFEiX"
   },
   "outputs": [],
   "source": [
    "# change to standard datetime format\n",
    "df_add.ADMITTIME = pd.to_datetime(df_add.ADMITTIME)\n",
    "df_add.DISCHTIME = pd.to_datetime(df_add.DISCHTIME)\n",
    "\n",
    "# remove elective admissions- we only want urgent and emergency\n",
    "df_adm = df_add.loc[df_add.ADMISSION_TYPE != 'ELECTIVE']\n",
    "\n",
    "# sort by subject id and admittime\n",
    "df_adm = df_add.sort_values(['SUBJECT_ID','ADMITTIME'])\n",
    "df_adm = df_adm.reset_index(drop = True)\n",
    "\n",
    "# add a column for next admit_time (readmissions) and readmission id\n",
    "df_adm['NEXT_ADMITTIME'] = df_adm.groupby('SUBJECT_ID').ADMITTIME.shift(-1)\n",
    "df_adm['NEXT_HADM_ID'] = df_adm.groupby('SUBJECT_ID').HADM_ID.shift(-1)\n",
    "df_adm = df_adm.sort_values(['SUBJECT_ID','ADMITTIME'])\n",
    "\n",
    "# Back fill. This will take a little while.\n",
    "df_adm[['NEXT_ADMITTIME','NEXT_HADM_ID']] = df_adm.groupby(['SUBJECT_ID'])[['NEXT_ADMITTIME','NEXT_HADM_ID']].fillna(method = 'bfill')\n",
    "df_adm['DAYS_TIL_NEXT_ADMIT'] = (df_adm.NEXT_ADMITTIME - df_adm.DISCHTIME).dt.total_seconds()/(24*60*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56561a61",
   "metadata": {
    "id": "56561a61"
   },
   "source": [
    "# notes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7pP74HChU3ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pP74HChU3ef",
    "outputId": "37811dcf-f23d-4f63-d9e7-29327b0883b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narjum2\\AppData\\Local\\Temp\\ipykernel_18732\\3117171214.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_notes_dis_sum['SUBJECT_ID'] = df_notes_dis_sum['SUBJECT_ID'].astype(int)\n",
      "C:\\Users\\narjum2\\AppData\\Local\\Temp\\ipykernel_18732\\3117171214.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_notes_dis_sum['HADM_ID'] = df_notes_dis_sum['HADM_ID'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Choosing only discharge summary clinical notes\n",
    "df_notes_dis_sum = df_notes.loc[df_notes.CATEGORY == 'Discharge summary'] # 2083180 -> 59652; \n",
    "\n",
    "# changing type to ints so it aligns with the datatype of the other dataframes\n",
    "df_notes_dis_sum['SUBJECT_ID'] = df_notes_dis_sum['SUBJECT_ID'].astype(int)\n",
    "df_notes_dis_sum['HADM_ID'] = df_notes_dis_sum['HADM_ID'].astype(int)\n",
    "\n",
    "# selecting the last discharge summary for each admission, if there are multiple\n",
    "df_notes_dis_sum_last = (df_notes_dis_sum.groupby(['SUBJECT_ID','HADM_ID']).nth(-1)).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RNCoYZoKFQqX",
   "metadata": {
    "id": "RNCoYZoKFQqX"
   },
   "source": [
    "# merging notes, admissions, and diagnoses df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1eTooxK_FNGz",
   "metadata": {
    "id": "1eTooxK_FNGz"
   },
   "outputs": [],
   "source": [
    "# first selecting admissions for subjects that have hf\n",
    "df_hf_adm = df_adm.loc[df_adm.SUBJECT_ID.isin(hf_pid_list)] # now 58976 -> 51113 -> 45321 -> 14746 rows of data\n",
    "\n",
    "# concatenating ICD-9 codes for patient admissions with multiple hf diagnoses\n",
    "df_subj_concat_icd_codes = df_codes[['SUBJECT_ID', 'HADM_ID', 'ICD9_CODE']].copy()\n",
    "df_subj_concat_icd_codes = df_subj_concat_icd_codes.groupby(['SUBJECT_ID', 'HADM_ID'])['ICD9_CODE'].agg(' '.join).reset_index() # # 651047 -> 21274 -> 14040 rows of data\n",
    "\n",
    "# merge the admissions and icd9-codes tables to get admissions involving hf diagnoses\n",
    "df_hf_admissions = pd.merge(df_adm[['SUBJECT_ID','HADM_ID','ADMITTIME','DISCHTIME','ADMISSION_TYPE','DEATHTIME', 'NEXT_ADMITTIME', 'NEXT_HADM_ID', 'DAYS_TIL_NEXT_ADMIT']],\n",
    "                        df_subj_concat_icd_codes, \n",
    "                        on = ['SUBJECT_ID', 'HADM_ID'],\n",
    "                        how = 'inner')\n",
    "# merge the admissions+icd-9 codes table with the discharge sumaries\n",
    "df_hf_adm_notes = pd.merge(df_hf_admissions[['SUBJECT_ID','HADM_ID', 'NEXT_ADMITTIME', 'NEXT_HADM_ID', 'DAYS_TIL_NEXT_ADMIT']], df_notes_dis_sum_last, \n",
    "                        on = ['SUBJECT_ID', 'HADM_ID'],\n",
    "                        how = 'inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "L9zCeoXjVKxK",
   "metadata": {
    "id": "L9zCeoXjVKxK"
   },
   "outputs": [],
   "source": [
    "# finally, create a labels for 30-day readmission\n",
    "df_hf_adm_notes['OUTPUT_LABEL'] = (df_hf_adm_notes.DAYS_TIL_NEXT_ADMIT < 30).astype('int') # consists of ____ 30-day readmission rows, and ___ without 30-day readmission rows\n",
    "\n",
    "# drop unnecessary columns\n",
    "df_hf_adm_notes.drop(columns=['NEXT_ADMITTIME', 'NEXT_HADM_ID', 'ROW_ID', 'CHARTDATE', 'CHARTTIME', 'STORETIME', 'CATEGORY', 'DESCRIPTION', 'CGID', 'ISERROR', 'DAYS_TIL_NEXT_ADMIT'] )\n",
    "\n",
    "df_hf_adm_notes['id'] = df_hf_adm_notes.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a5139f",
   "metadata": {
    "id": "37a5139f"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8fa3a724",
   "metadata": {
    "id": "8fa3a724"
   },
   "outputs": [],
   "source": [
    "# # shuffle input\n",
    "df_adm_notes_merged = df_hf_adm_notes.sample(n=len(df_hf_adm_notes), random_state=42)\n",
    "df_adm_notes_merged = df_adm_notes_merged.reset_index(drop=True)\n",
    "\n",
    "# finalized dataset\n",
    "df_final = df_adm_notes_merged.copy(deep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cc2092",
   "metadata": {},
   "source": [
    "Preprocessing text to remove any HTML tags, non-word characters, numbers and convert all text to lowercase and tokenzies notes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ZC4RBfaQPH5X",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZC4RBfaQPH5X",
    "outputId": "4b8ef3f4-d4bc-4bab-db74-3bcb6854d4ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13755"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) \n",
    "    text = re.sub(\" \\d+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "#replace notes column with processed text\n",
    "df_final['text2'] = df_final['TEXT'].apply(preprocessor)\n",
    "\n",
    "# Create tokens\n",
    "token_review=[]\n",
    "for i in range(df_final['text2'].shape[0]):\n",
    "    review = df_final['text2'][i]\n",
    "    token_review.append([i for i in review.split()])\n",
    "\n",
    "#list of lists, were each list contains the tokens for notes in each row\n",
    "len(token_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3647fb59",
   "metadata": {},
   "source": [
    "# Word2Vec and CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a57e3fd",
   "metadata": {},
   "source": [
    "Train word2Vec model on tokenzied notes from dataset references: https://github.com/lsy3/clinical-notes-diagnosis-dl-nlp, https://www.kaggle.com/code/jagannathrk/word2vec-cnn-text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "Uq79BBtnvHUR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uq79BBtnvHUR",
    "outputId": "b21be84a-235c-469b-d00e-9a0e9cc17ebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for Word2vec training:  90.208571434021 seconds.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim import utils\n",
    "from time import time\n",
    "import random\n",
    "\n",
    "size = 300  #change to 100 and 600 to generate vectors with those dimensions\n",
    "\n",
    "#instantiate our  model\n",
    "model_w2v = Word2Vec(min_count=10, window=5, vector_size=size, sample=1e-3, negative=5, workers=4, sg=0)\n",
    "\n",
    "#build vocab over all reviews\n",
    "model_w2v.build_vocab(token_review)\n",
    "\n",
    "#We pass through the data set multiple times, shuffling the training reviews each time to improve accuracy.\n",
    "Idx=list(range(len(token_review)))\n",
    "\n",
    "t0 = time()\n",
    "perm_sentences = [token_review[i] for i in Idx]\n",
    "model_w2v.train(perm_sentences,total_examples=model_w2v.corpus_count,epochs=5)\n",
    "elapsed=time() - t0\n",
    "print(\"Time taken for Word2vec training: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "61c94b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        admission date    discharge date    date of bi...\n",
       "1        admission date    discharge date    date of bi...\n",
       "2        admission date    discharge date    date of bi...\n",
       "3        admission date    discharge date    date of bi...\n",
       "4        admission date    discharge date    date of bi...\n",
       "                               ...                        \n",
       "13750    admission date    discharge date    date of bi...\n",
       "13751    admission date    discharge date    date of bi...\n",
       "13752    admission date    discharge date    date of bi...\n",
       "13753    admission date    discharge date    date of bi...\n",
       "13754    admission date    discharge date    date of bi...\n",
       "Name: text2, Length: 13755, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['text2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0l9sQl6EF7OD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0l9sQl6EF7OD",
    "outputId": "bf308e4e-44f5-4612-9e33-047e3f967eaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  152   920   713    48    66    29    48   507   559   277   143    47\n",
      "     58   508   924   138    14  2514  1877    55    47   988     3  1352\n",
      "      4   446   924   476   837   587  2771  1103   491   432  6510    49\n",
      "     88   476   837   587   521   587   122   419   117   109    49    88\n",
      "      6    94    33    22   101    77    20    10  2771  1103    20     6\n",
      "     94    33    22   101   156   103    51   494    22   800   156   103\n",
      "   1161   425    42]\n",
      " [  331     1    15     5   100    42     1 11988    22   244   712     8\n",
      "     20     1   137  2531    50  3760     1   289    94    33    22   101\n",
      "     33    22   101  2346    66     8    43   793     9    17   208     9\n",
      "     62   638     9    17  2145     9    17   135     9   141   148   991\n",
      "    610    17   141  2123   846     9  7162   172    52  1756   212   141\n",
      "  11466   172    52    28   309   712    28   220   712    28   206    28\n",
      "    143   425    42]]\n"
     ]
    }
   ],
   "source": [
    "#Create input sequeces for notes and pad sequences \n",
    "words=list(model_w2v.wv.index_to_key)\n",
    "# len(words)\n",
    "len_vocab = len(words)\n",
    "token = Tokenizer(len_vocab)\n",
    "token.fit_on_texts(df_final['text2'])\n",
    "text = token.texts_to_sequences(df_final['text2'])\n",
    "text = pad_sequences(text, 75)\n",
    "print(text[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82797954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create input sequeces for output label\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(df_final['OUTPUT_LABEL'])\n",
    "y = to_categorical(y)\n",
    "y[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "653eaf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset to test and train sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(text), y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bd9e9b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2751"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train) #11004\n",
    "len(y_test) #2751\n",
    "len(x_train) #11004\n",
    "len(x_test) #2751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f5ff63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def gensim_to_keras_embedding(model, train_embeddings=False):\n",
    "    \"\"\"Get a Keras 'Embedding' layer with weights set from Word2Vec model's learned word embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_embeddings : bool\n",
    "        If False, the returned weights are frozen and stopped from being updated.\n",
    "        If True, the weights can / will be further updated in Keras.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `keras.layers.Embedding`\n",
    "        Embedding layer, to be used as input to deeper network layers.\n",
    "\n",
    "    \"\"\"\n",
    "    keyed_vectors = model  # structure holding the result of training\n",
    "    weights = keyed_vectors.vectors  # vectors themselves, a 2D numpy array    \n",
    "    index_to_key = keyed_vectors.index_to_key  # which row in `weights` corresponds to which word?\n",
    "\n",
    "    layer = Embedding(\n",
    "        input_dim=weights.shape[0],\n",
    "        output_dim=weights.shape[1],\n",
    "        weights=[weights],\n",
    "        trainable=train_embeddings,\n",
    "    )\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fb6901b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "688/688 [==============================] - 65s 92ms/step - loss: 0.3106 - acc: 0.9161 - val_loss: 0.3263 - val_acc: 0.9168\n",
      "Epoch 2/3\n",
      "688/688 [==============================] - 60s 87ms/step - loss: 0.2833 - acc: 0.9168 - val_loss: 0.2878 - val_acc: 0.9168\n",
      "Epoch 3/3\n",
      "688/688 [==============================] - 60s 87ms/step - loss: 0.2789 - acc: 0.9168 - val_loss: 0.2810 - val_acc: 0.9168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20091f4bfd0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model = Sequential()\n",
    "keras_model.add(gensim_to_keras_embedding(model_w2v.wv,True))\n",
    "keras_model.add(Dropout(0.2))\n",
    "keras_model.add(Conv1D(filters=50, kernel_size=1, activation='relu', padding='same', strides=1))\n",
    "keras_model.add(MaxPool1D())\n",
    "keras_model.add(Dropout(0.2))\n",
    "keras_model.add(Conv1D(filters=100, kernel_size=2, activation='relu', padding='same', strides=1))\n",
    "keras_model.add(MaxPool1D())\n",
    "keras_model.add(Dropout(0.2))\n",
    "keras_model.add(Conv1D(filters=200, kernel_size=3, activation='relu', padding='same', strides=1))\n",
    "keras_model.add(GlobalMaxPool1D())\n",
    "keras_model.add(Dropout(0.2))\n",
    "keras_model.add(Dense(2))\n",
    "keras_model.add(Activation('softmax'))\n",
    "keras_model.compile(loss='binary_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "keras_model.fit(x_train, y_train, batch_size=16, epochs=3, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89d8e63",
   "metadata": {},
   "source": [
    "# Evalution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "949adc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = np.argmax(keras_model.predict(x_test),axis=1)\n",
    "y_true = []\n",
    "for i in y_test:\n",
    "    if(i[0] == 1):\n",
    "        y_true.append(0)\n",
    "    else:\n",
    "        y_true.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "95ccc7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narjum2\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\narjum2\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\narjum2\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.916758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956571</td>\n",
       "      <td>2522.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.916758</td>\n",
       "      <td>0.916758</td>\n",
       "      <td>0.916758</td>\n",
       "      <td>0.916758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.458379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.478286</td>\n",
       "      <td>2751.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.840444</td>\n",
       "      <td>0.916758</td>\n",
       "      <td>0.876944</td>\n",
       "      <td>2751.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.916758  1.000000  0.956571  2522.000000\n",
       "1              0.000000  0.000000  0.000000   229.000000\n",
       "accuracy       0.916758  0.916758  0.916758     0.916758\n",
       "macro avg      0.458379  0.500000  0.478286  2751.000000\n",
       "weighted avg   0.840444  0.916758  0.876944  2751.000000"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_report1=classification_report(y_true,Y_pred,output_dict=True)\n",
    "df_cnn1=pd.DataFrame(cnn_report1).transpose()\n",
    "df_cnn1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae61a39",
   "metadata": {},
   "source": [
    "# Word2Vec (clinical-embeddings) + CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5879ba8",
   "metadata": {},
   "source": [
    " reference: https://pubmed.ncbi.nlm.nih.gov/34920127/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a79888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText, Word2Vec, KeyedVectors # KeyedVectors are used to load the GloVe models\n",
    "\n",
    "# Load the model\n",
    "model = Word2Vec.load('w2v_oa_cr_100d.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a058546d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "688/688 [==============================] - 379s 524ms/step - loss: 0.2873 - acc: 0.9158 - val_loss: 0.2860 - val_acc: 0.9168\n",
      "Epoch 2/3\n",
      "688/688 [==============================] - 356s 518ms/step - loss: 0.2740 - acc: 0.9168 - val_loss: 0.2827 - val_acc: 0.9168\n",
      "Epoch 3/3\n",
      "688/688 [==============================] - 357s 520ms/step - loss: 0.2677 - acc: 0.9168 - val_loss: 0.2809 - val_acc: 0.9168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x200b27db580>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model = Sequential()\n",
    "keras_model.add(gensim_to_keras_embedding(model.wv,True))\n",
    "keras_model.add(Dropout(0.2))\n",
    "keras_model.add(Conv1D(filters=50, kernel_size=1, activation='relu', padding='same', strides=1))\n",
    "keras_model.add(MaxPool1D())\n",
    "keras_model.add(Dropout(0.2))\n",
    "keras_model.add(Conv1D(filters=100, kernel_size=2, activation='relu', padding='same', strides=1))\n",
    "keras_model.add(MaxPool1D())\n",
    "keras_model.add(Dropout(0.2))\n",
    "keras_model.add(Conv1D(filters=200, kernel_size=3, activation='relu', padding='same', strides=1))\n",
    "keras_model.add(GlobalMaxPool1D())\n",
    "keras_model.add(Dropout(0.2))\n",
    "keras_model.add(Dense(2))\n",
    "keras_model.add(Activation('softmax'))\n",
    "keras_model.compile(loss='binary_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "keras_model.fit(x_train, y_train, batch_size=16, epochs=3, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5591c6",
   "metadata": {},
   "source": [
    "# Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5b238601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = np.argmax(keras_model.predict(x_test),axis=1)\n",
    "y_true = []\n",
    "for i in y_test:\n",
    "    if(i[0] == 1):\n",
    "        y_true.append(0)\n",
    "    else:\n",
    "        y_true.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8f615dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narjum2\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\narjum2\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\narjum2\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.916758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956571</td>\n",
       "      <td>2522.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.916758</td>\n",
       "      <td>0.916758</td>\n",
       "      <td>0.916758</td>\n",
       "      <td>0.916758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.458379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.478286</td>\n",
       "      <td>2751.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.840444</td>\n",
       "      <td>0.916758</td>\n",
       "      <td>0.876944</td>\n",
       "      <td>2751.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.916758  1.000000  0.956571  2522.000000\n",
       "1              0.000000  0.000000  0.000000   229.000000\n",
       "accuracy       0.916758  0.916758  0.916758     0.916758\n",
       "macro avg      0.458379  0.500000  0.478286  2751.000000\n",
       "weighted avg   0.840444  0.916758  0.876944  2751.000000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_report2 =classification_report(y_true,Y_pred,output_dict=True)\n",
    "df_cnn2=pd.DataFrame(cnn_report2).transpose()\n",
    "df_cnn2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac3b411",
   "metadata": {},
   "source": [
    "# Tf-idf and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "851136be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794\n",
    "# https://www.kaggle.com/code/onadegibert/sentiment-analysis-with-tfidf-and-random-forest\n",
    "## for processing\n",
    "import re\n",
    "import nltk\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
    "\n",
    "# split into test and training df\n",
    "dtf_train, dtf_test = model_selection.train_test_split(df_final, test_size=0.2)\n",
    "\n",
    "# ## get target values\n",
    "y_train = dtf_train[\"OUTPUT_LABEL\"].values\n",
    "y_test = dtf_test[\"OUTPUT_LABEL\"].values\n",
    "X_train = dtf_train[\"text2\"]\n",
    "X_test = dtf_test[\"text2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ae428082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.316975645219921\n",
      "1144\n",
      "1144\n"
     ]
    }
   ],
   "source": [
    "print((df_final.OUTPUT_LABEL.sum()/len(df_final))*100)\n",
    "\n",
    "print(df_final.OUTPUT_LABEL.sum())\n",
    "\n",
    "print(df_final.OUTPUT_LABEL.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c40f6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform training data into tf-idf vector - takes 1 minute to run\n",
    "vectorizer = feature_extraction.text.TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "corpus = X_train # make sure using the right train data\n",
    "vectorizer.fit(corpus)\n",
    "X_train = vectorizer.transform(corpus)\n",
    "dic_vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8d4cb525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00260757",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eae3e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d56fd99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = rf.predict(x_test)\n",
    "ones = [x for x in predicted if x ==1]\n",
    "len(ones)\n",
    "ones = [x for x in y_test if x ==1]\n",
    "len(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a845b6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narjum2\\AppData\\Local\\Temp\\ipykernel_18732\\321286341.py:4: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df.to_latex()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.952756</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.711765</td>\n",
       "      <td>1278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100977</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.174157</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.572674</td>\n",
       "      <td>0.572674</td>\n",
       "      <td>0.572674</td>\n",
       "      <td>0.572674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.526867</td>\n",
       "      <td>0.600364</td>\n",
       "      <td>0.442961</td>\n",
       "      <td>1376.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.892091</td>\n",
       "      <td>0.572674</td>\n",
       "      <td>0.673476</td>\n",
       "      <td>1376.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.952756  0.568075  0.711765  1278.000000\n",
       "1              0.100977  0.632653  0.174157    98.000000\n",
       "accuracy       0.572674  0.572674  0.572674     0.572674\n",
       "macro avg      0.526867  0.600364  0.442961  1376.000000\n",
       "weighted avg   0.892091  0.572674  0.673476  1376.000000"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, predicted, output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df.to_latex()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2eea04ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5268665521044397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "precision,recall,fscore,support=score(y_test, predicted,average='macro')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "39659060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.952756</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.711765</td>\n",
       "      <td>1278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.892091</td>\n",
       "      <td>0.572674</td>\n",
       "      <td>0.673476</td>\n",
       "      <td>1376.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.572674</td>\n",
       "      <td>0.572674</td>\n",
       "      <td>0.572674</td>\n",
       "      <td>0.572674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.526867</td>\n",
       "      <td>0.600364</td>\n",
       "      <td>0.442961</td>\n",
       "      <td>1376.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100977</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.174157</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.952756  0.568075  0.711765  1278.000000\n",
       "weighted avg   0.892091  0.572674  0.673476  1376.000000\n",
       "accuracy       0.572674  0.572674  0.572674     0.572674\n",
       "macro avg      0.526867  0.600364  0.442961  1376.000000\n",
       "1              0.100977  0.632653  0.174157    98.000000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_classification_report(y_test, y_pred):\n",
    "    '''Source: https://stackoverflow.com/questions/39662398/scikit-learn-output-metrics-classification-report-into-csv-tab-delimited-format'''\n",
    "    from sklearn import metrics\n",
    "    report = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "    df_classification_report = pd.DataFrame(report).transpose()\n",
    "    df_classification_report = df_classification_report.sort_values(by=['f1-score'], ascending=False)\n",
    "    return df_classification_report\n",
    "\n",
    "get_classification_report(y_test, predicted)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
